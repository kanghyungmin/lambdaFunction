import requests
import pandas as pd
from bs4 import BeautifulSoup
import re

# HTML ì •ì œ í•¨ìˆ˜
def clean_html(html):
    soup = BeautifulSoup(html, "html.parser")

    # <p class="bold">ë¥¼ ê´„í˜¸ë¡œ ì²˜ë¦¬
    for p in soup.find_all("p", class_="bold"):
        p.replace_with(f"({p.get_text(strip=True)})")

    # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    text = soup.get_text(separator=', ', strip=True)

    # ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ì‰¼í‘œ, ê³µë°± ì •ë¦¬
    text = re.sub(r',\s*,', ', ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# ê³µí†µ API ì •ë³´
base_url = "https://foodqr.kr/openapi/service/qr1007/F007"
params = {
    "accessKey": "",
    "numOfRows": 10,
    "_type": "json"
}

all_items = []

# í˜ì´ì§€ ë°˜ë³µ
for page in range(1, 24):
    print(f"ğŸ“¦ Fetching page {page}")
    params["pageNo"] = page
    response = requests.get(base_url, params=params)
    response.raise_for_status()

    data = response.json()
    items = data['response']['body']['items']['item']
    if isinstance(items, dict):  # ë‹¨ì¼ itemì¼ ê²½ìš°
        items = [items]

    for item in items:
        if "prvwCn" in item:
            item["cleanPrvwCn"] = clean_html(item["prvwCn"])
        else:
            item["cleanPrvwCn"] = None
        all_items.append(item)

# DataFrame ìƒì„± ë° ì €ì¥
df = pd.DataFrame(all_items)
df.to_excel("cleaned_food_items.xlsx", index=False)

print("âœ… ëª¨ë“  í˜ì´ì§€ ë°ì´í„°ë¥¼ 'cleaned_food_items.xlsx'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")